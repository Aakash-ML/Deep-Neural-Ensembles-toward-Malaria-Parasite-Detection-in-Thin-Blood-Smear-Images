{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates and stores a single model ensemble created from a selection of models. We used a customized CNN, and pretrained models including VGG19, InceptionResnetV2 and SqueezeNet, with their ImageNet weights initialized and fine-tuned end-to-end. The optimal model ensemble is chosen and saved to make further predictions. Five fold cross validation is performed on a patient-specific case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "from keras.models import Model, Input\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Average, BatchNormalization, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras_squeezenet import SqueezeNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import load_model\n",
    "from keras import applications\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to plot confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False, #if true all values in confusion matrix is between 0 and 1\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Loading the data\n",
    "\n",
    "img_width, img_height = 100, 100\n",
    "train_data_dir = 'malaria100/train'\n",
    "validation_data_dir = 'malaria100/test'\n",
    "epochs = 60\n",
    "batch_size = 16 \n",
    "num_classes= 2\n",
    "\n",
    "# Since the models work with the data of the same shape, we \n",
    "#define a single input layer that will be used by every model.\n",
    "\n",
    "input_shape = (100,100,3)\n",
    "model_input = Input(shape=input_shape)\n",
    "print(model_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% declaring image data generators\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=2,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.5,\n",
    "      horizontal_flip=True,\n",
    "      vertical_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(100,100),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(100,100),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',shuffle=False)\n",
    "\n",
    "#identify the number of samples\n",
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_validation_samples = len(validation_generator.filenames)\n",
    "\n",
    "#check the class indices\n",
    "train_generator.class_indices\n",
    "validation_generator.class_indices\n",
    "\n",
    "#true labels\n",
    "Y_test=validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% assign class weights to balance model training and penalize over-represented classes\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(train_generator.classes), \n",
    "                train_generator.classes)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% define custom model and instantiate it\n",
    "\n",
    "def custom_cnn(model_input):\n",
    "    x = BatchNormalization()(model_input)\n",
    "    x = Conv2D(64, (5, 5), padding='same', activation='relu', name = 'custom_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2,2), name = 'maxpool1')(x)\n",
    "    x = Dropout(0.25, name = 'conv_dropout1')(x)\n",
    "    x = BatchNormalization(name = 'custom_batchnorm1')(x)\n",
    "    x = Conv2D(128, (5, 5), padding='same', activation='relu', name = 'custom_conv2')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name = 'maxpool2')(x)\n",
    "    x = Dropout(0.25, name = 'conv_dropout2')(x)\n",
    "    x = BatchNormalization(name = 'custom_batchnorm2')(x)\n",
    "    x = Conv2D(256, (5, 5), padding='same', activation='relu', name = 'custom_conv3')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name = 'maxpool3')(x)\n",
    "    x = Dropout(0.25, name = 'conv_dropout3')(x)\n",
    "    x = GlobalAveragePooling2D(name = 'custom_GAP')(x)\n",
    "    x = Dense(256, activation='relu', name = 'custom_dense1')(x)\n",
    "    x = Dropout(0.5, name = 'dense_dropout1')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name = 'custom_dense2')(x)\n",
    "    model = Model(inputs=model_input, outputs=x, name='custom_cnn')\n",
    "    return model\n",
    "\n",
    "#instantiate the model\n",
    "custom_model = custom_cnn(model_input)\n",
    "\n",
    "#display model summary\n",
    "custom_model.summary()\n",
    "\n",
    "#plot the model\n",
    "plot_model(custom_model, to_file='custom_model.png',show_shapes=True, show_layer_names=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% VGG19 model \n",
    "\n",
    "def vgg19_cnn(model_input):\n",
    "    vgg19_cnn = VGG19(weights='imagenet', include_top=False, input_tensor=model_input)\n",
    "    x = vgg19_cnn.layers[-2].output \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=vgg19_cnn.input, outputs=predictions, name='vgg19_custom')\n",
    "    return model\n",
    "\n",
    "#instantiate the model\n",
    "vgg19_custom_model = vgg19_cnn(model_input)\n",
    "\n",
    "#plot model summary\n",
    "vgg19_custom_model.summary()\n",
    "plot_model(vgg19_custom_model, to_file='vgg19_custom_model.png',show_shapes=True, show_layer_names=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SqueezeNet \n",
    "\n",
    "def squeeze_cnn(model_input):\n",
    "    squeeze_cnn = SqueezeNet(weights='imagenet', include_top=False, input_tensor=model_input)\n",
    "    x = squeeze_cnn.layers[-3].output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=squeeze_cnn.input, outputs=predictions, name='squeeze_custom')\n",
    "    return model\n",
    "\n",
    "#instantiate the model\n",
    "squeeze_custom_model = squeeze_cnn(model_input)\n",
    "\n",
    "#display model summary\n",
    "squeeze_custom_model.summary()\n",
    "\n",
    "#plot model\n",
    "plot_model(squeeze_custom_model, to_file='squeeze_custom_model.png',show_shapes=True, show_layer_names=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Inception ResnetV2 \n",
    "\n",
    "def incepres_cnn(model_input):\n",
    "    incepres_cnn = InceptionResNetV2(weights='imagenet', include_top=False, input_tensor=model_input)\n",
    "    x = incepres_cnn.layers[-3].output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=incepres_cnn.input, outputs=predictions, name='InceptionResnet_custom')\n",
    "    return model\n",
    "\n",
    "#instantiate the model\n",
    "inceptionresnet_custom_model = incepres_cnn(model_input)\n",
    "\n",
    "#display model summary\n",
    "inceptionresnet_custom_model.summary()\n",
    "\n",
    "#plot model\n",
    "plot_model(inceptionresnet_custom_model, to_file='inceptionresnet_custom_model.png',show_shapes=True, show_layer_names=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compile and train the custom model\n",
    "\n",
    "adam = Adam(lr=0.001)  \n",
    "custom_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "filepath = 'weights/' + custom_model.name + '.{epoch:02d}-{val_acc:.4f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_weights_only=False, save_best_only=True, mode='max', period=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=batch_size)\n",
    "callbacks_list = [checkpoint, tensor_board, reduce_lr]\n",
    "history = custom_model.fit_generator(train_generator, steps_per_epoch=nb_train_samples // batch_size,\n",
    "                                  epochs=epochs, validation_data=validation_generator,\n",
    "                                  class_weight = class_weights,\n",
    "                                  callbacks=callbacks_list, \n",
    "                                  validation_steps=nb_validation_samples // batch_size, verbose=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plt.plot(np.arange(1, N+1), history.history[\"loss\"], 'orange', label=\"train_loss\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"val_loss\"], 'red', label=\"val_loss\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"acc\"], 'blue', label=\"train_acc\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"val_acc\"], 'green', label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"custom_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compile and train the VGG19 model\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "vgg19_custom_model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy']) \n",
    "filepath = 'weights/' + vgg19_custom_model.name + '.{epoch:02d}-{val_acc:.4f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_weights_only=False, save_best_only=True, mode='max', period=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=batch_size)\n",
    "callbacks_list = [checkpoint, tensor_board, reduce_lr]\n",
    "history = vgg19_custom_model.fit_generator(train_generator, steps_per_epoch=nb_train_samples // batch_size,\n",
    "                                  epochs=epochs, validation_data=validation_generator,\n",
    "                                  class_weight = class_weights,\n",
    "                                  callbacks=callbacks_list, \n",
    "                                  validation_steps=nb_validation_samples // batch_size, verbose=1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plt.plot(np.arange(1, N+1), history.history[\"loss\"], 'orange', label=\"train_loss\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"val_loss\"], 'red', label=\"val_loss\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"acc\"], 'blue', label=\"train_acc\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"val_acc\"], 'green', label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"VGG19_custom_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compile and train the squeezenet model\n",
    "\n",
    "adam = Adam(lr=0.0001) \n",
    "squeeze_custom_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "filepath = 'weights/' + squeeze_custom_model.name + '.{epoch:02d}-{val_acc:.4f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_weights_only=False, save_best_only=True, mode='max', period=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=batch_size)\n",
    "callbacks_list = [checkpoint, tensor_board, reduce_lr]\n",
    "history = squeeze_custom_model.fit_generator(train_generator, steps_per_epoch=nb_train_samples // batch_size,\n",
    "                                  epochs=epochs, validation_data=validation_generator,\n",
    "                                  class_weight = class_weights,\n",
    "                                  callbacks=callbacks_list, \n",
    "                                  validation_steps=nb_validation_samples // batch_size, verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plt.plot(np.arange(1, N+1), history.history[\"loss\"], 'orange', label=\"train_loss\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"val_loss\"], 'red', label=\"val_loss\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"acc\"], 'blue', label=\"train_acc\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"val_acc\"], 'green', label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"SqueezeNet_custom_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compile and train the InceptionResnetV2 model\n",
    "\n",
    "adam = Adam(lr=0.0001)  \n",
    "inceptionresnet_custom_model.compile(optimizer=adam,\n",
    "                                     loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "filepath = 'weights/' + inceptionresnet_custom_model.name + '.{epoch:02d}-{val_acc:.4f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_weights_only=False, save_best_only=True, mode='max', period=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=batch_size)\n",
    "callbacks_list = [checkpoint, tensor_board, reduce_lr]\n",
    "history = inceptionresnet_custom_model.fit_generator(train_generator, steps_per_epoch=nb_train_samples // batch_size,\n",
    "                                  epochs=epochs, validation_data=validation_generator,\n",
    "                                  class_weight = class_weights,\n",
    "                                  callbacks=callbacks_list, \n",
    "                                  validation_steps=nb_validation_samples // batch_size, verbose=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plt.plot(np.arange(1, N+1), history.history[\"loss\"], 'orange', label=\"train_loss\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"val_loss\"], 'red', label=\"val_loss\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"acc\"], 'blue', label=\"train_acc\")\n",
    "plt.plot(np.arange(1, N+1), history.history[\"val_acc\"], 'green', label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"InceptionResnet_custom_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model by loading the best weights\n",
    "custom_model.load_weights('weights/custom_cnn.15-0.9919.h5')\n",
    "\n",
    "#evaluate accuracy\n",
    "custom_y_pred = custom_model.predict_generator(validation_generator,\n",
    "                                               nb_validation_samples/batch_size, workers=1)\n",
    "accuracy = accuracy_score(Y_test,custom_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Custom model is: ', accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "custom_mse = mean_squared_error(Y_test,custom_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Custom model is: ', custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "custom_msle = mean_squared_log_error(Y_test,custom_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Custom model is: ', custom_msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,custom_y_pred.argmax(axis=-1),\n",
    "                            target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,custom_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, custom_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(20,10), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristics for Custom model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model by loading the best weights \n",
    "vgg19_custom_model.load_weights('weights/vgg19_custom.45-0.9963.h5')\n",
    "\n",
    "#evaluate accuracy\n",
    "vgg19_custom_y_pred = vgg19_custom_model.predict_generator(validation_generator,\n",
    "                                                           nb_validation_samples/batch_size, workers=1)\n",
    "vgg19_accuracy = accuracy_score(Y_test,vgg19_custom_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the VGG19 Custom model is: ', vgg19_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "vgg19_custom_mse = mean_squared_error(Y_test,vgg19_custom_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the VGG19 Custom model is: ', vgg19_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "vgg19_custom_msle = mean_squared_log_error(Y_test,vgg19_custom_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the VGG19 Custom model is: ', vgg19_custom_msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,vgg19_custom_y_pred.argmax(axis=-1),\n",
    "                            target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,vgg19_custom_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, vgg19_custom_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(20,10), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristics for VGG19 Custom model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model by loading the best weights \n",
    "squeeze_custom_model.load_weights('weights/squeeze_custom.11-0.9948.h5')\n",
    "\n",
    "#evaluate accuracy\n",
    "\n",
    "squeeze_y_pred = squeeze_custom_model.predict_generator(validation_generator,\n",
    "                                                        nb_validation_samples/batch_size, workers=1)\n",
    "squeeze_accuracy = accuracy_score(Y_test,squeeze_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the SqueezeNet Custom model is: ', squeeze_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "\n",
    "squeeze_custom_mse = mean_squared_error(Y_test,squeeze_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the SqueezeNet Custom model is: ', squeeze_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "\n",
    "squeeze_custom_msle = mean_squared_log_error(Y_test,squeeze_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the SqueezeNet Custom model is: ', squeeze_custom_msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,squeeze_y_pred.argmax(axis=-1),\n",
    "                            target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,squeeze_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, squeeze_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(20,10), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristics for SqueezeNet Custom model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model by loading the best weights \n",
    "inceptionresnet_custom_model.load_weights('weights/InceptionResnet_custom.15-0.9956.h5')\n",
    "\n",
    "#evaluate accuracy\n",
    "incepres_y_pred = inceptionresnet_custom_model.predict_generator(validation_generator,\n",
    "                                                                 nb_validation_samples/batch_size, workers=1)\n",
    "incepres_accuracy = accuracy_score(Y_test,incepres_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the InceptionResNetV2 Custom model is: ', incepres_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "incepres_custom_mse = mean_squared_error(Y_test,incepres_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the InceptionResNetv2 Custom model is: ', incepres_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "incepres_custom_msle = mean_squared_log_error(Y_test,incepres_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the InceptionResNetv2 Custom model is: ', incepres_custom_msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,incepres_y_pred.argmax(axis=-1),\n",
    "                            target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,incepres_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, incepres_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(20,10), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristics for InceptionResNetV2 Custom model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% construct the ensemble model\n",
    "custom_model = custom_cnn(model_input)\n",
    "vgg19_custom_model = vgg19_cnn(model_input)\n",
    "squeeze_custom_model = squeeze_cnn(model_input)\n",
    "inceptionresnet_custom_model = incepres_cnn(model_input)\n",
    "\n",
    "#load the best weights\n",
    "custom_model.load_weights('weights/custom_cnn.15-0.9919.h5')\n",
    "vgg19_custom_model.load_weights('weights/vgg19_custom.45-0.9963.h5')\n",
    "squeeze_custom_model.load_weights('weights/squeeze_custom.11-0.9948.h5')\n",
    "inceptionresnet_custom_model.load_weights('weights/InceptionResnet_custom.15-0.9956.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% modify squeezenet layer name to avoid common names while forming ensemble\n",
    "\n",
    "squeeze_custom_model.get_layer(name='conv1').name='conv1SQUEEZE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the models to the list\n",
    "\n",
    "models = [custom_model, vgg19_custom_model, squeeze_custom_model, inceptionresnet_custom_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble model definition is very straightforward. It uses the same input layer thas is shared between all previous models. \n",
    "In the top layer, the ensemble computes the average of three models' outputs (predictions) by using Average() layer. The ensemble is expected to have a lower error rate than any single model and better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(models, model_input):\n",
    "    \n",
    "    outputs = [m.output for m in models]\n",
    "    print(outputs)\n",
    "    y = Average()(outputs) \n",
    "    model = Model(model_input, y, name='ensemble')\n",
    "    return model\n",
    "\n",
    "#istantitate the ensemble model and report the summary\n",
    "ensemble_model = ensemble(models,model_input)\n",
    "\n",
    "#save the ensemble model with the architecture and the weights together\n",
    "ensemble_model.save('weights/ensemblemodel.h5')\n",
    "print('The Ensemble Model is Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load the ensemble model and make predictions on the test data\n",
    "ensemble_model=load_model('weights/ensemblemodel.h5')\n",
    "ensemble_model.summary()\n",
    "plot_model(ensemble_model, to_file='ensemble_model.png',show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate accuracy\n",
    "ensem_y_pred = ensemble_model.predict_generator(validation_generator,\n",
    "                                                nb_validation_samples/batch_size, workers=1)\n",
    "ensemble_model_accuracy = accuracy_score(Y_test,ensem_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Ensemble model is: ', ensemble_model_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "ensemble_model_custom_mse = mean_squared_error(Y_test,ensem_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Ensemble model is: ', ensemble_model_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "ensemble_model_custom_msle = mean_squared_log_error(Y_test,ensem_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Ensemble model is: ', ensemble_model_custom_msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,ensem_y_pred.argmax(axis=-1),target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,ensem_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compute the ROC-AUC values\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, ensem_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(15,10), dpi=100)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristics for the Ensemble model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Other Possible Ensembles: \n",
    "# We can select the optimal ensemble from the collection of model combinations\n",
    "\n",
    "pair_A = [custom_model, vgg19_custom_model]\n",
    "pair_B = [custom_model, squeeze_custom_model]\n",
    "pair_C = [custom_model, inceptionresnet_custom_model]\n",
    "pair_D = [vgg19_custom_model, squeeze_custom_model]\n",
    "pair_E = [vgg19_custom_model, inceptionresnet_custom_model]\n",
    "pair_F = [squeeze_custom_model, inceptionresnet_custom_model]\n",
    "pair_G = [custom_model, vgg19_custom_model, squeeze_custom_model]\n",
    "pair_H = [custom_model, vgg19_custom_model, inceptionresnet_custom_model]\n",
    "pair_I = [vgg19_custom_model, squeeze_custom_model, inceptionresnet_custom_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% evaluate the performance of these paired ensembles\n",
    "\n",
    "pair_A_ensemble_model = ensemble(pair_A, model_input)\n",
    "pair_A_ensemble_model.save('weights/ensemblemodel_pairA.h5')\n",
    "print('The Ensemble Model is Saved')\n",
    "\n",
    "#evaluate accuracy\n",
    "A_ensem_y_pred = pair_A_ensemble_model.predict_generator(validation_generator,\n",
    "                                                         nb_validation_samples/batch_size, workers=1)\n",
    "A_ensemble_model_accuracy = accuracy_score(Y_test,A_ensem_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Pair A Ensemble model is: ', A_ensemble_model_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "A_ensemble_model_custom_mse = mean_squared_error(Y_test,A_ensem_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Pair A Ensemble model is: ', A_ensemble_model_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "A_ensemble_model_custom_msle = mean_squared_log_error(Y_test,A_ensem_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Pair A Ensemble model is: ', A_ensemble_model_custom_msle)\n",
    "\n",
    "#print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)']\n",
    "print(classification_report(Y_test,A_ensem_y_pred.argmax(axis=-1),target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,A_ensem_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, A_ensem_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(20,10), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Pair B \n",
    "\n",
    "pair_B_ensemble_model = ensemble(pair_B, model_input)\n",
    "pair_B_ensemble_model.save('weights/ensemblemodel_pairB.h5')\n",
    "print('The Ensemble Model is Saved')\n",
    "\n",
    "#evaluate accuracy\n",
    "B_ensem_y_pred = pair_B_ensemble_model.predict_generator(validation_generator,\n",
    "                                                         nb_validation_samples/batch_size, workers=1)\n",
    "B_ensemble_model_accuracy = accuracy_score(Y_test,B_ensem_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Pair B Ensemble model is: ', B_ensemble_model_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "B_ensemble_model_custom_mse = mean_squared_error(Y_test,B_ensem_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Pair B Ensemble model is: ', B_ensemble_model_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "B_ensemble_model_custom_msle = mean_squared_log_error(Y_test,B_ensem_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Pair B Ensemble model is: ', B_ensemble_model_custom_msle)\n",
    "\n",
    "#print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)']\n",
    "print(classification_report(Y_test,B_ensem_y_pred.argmax(axis=-1),target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,B_ensem_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, B_ensem_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(15,10), dpi=100)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Pair C\n",
    "\n",
    "pair_C_ensemble_model = ensemble(pair_C, model_input)\n",
    "pair_C_ensemble_model.save('weights/ensemblemodel_pairC.h5')\n",
    "print('The Ensemble Model is Saved')\n",
    "\n",
    "#evaluate accuracy\n",
    "C_ensem_y_pred = pair_C_ensemble_model.predict_generator(validation_generator,\n",
    "                                                         nb_validation_samples/batch_size, workers=1)\n",
    "C_ensemble_model_accuracy = accuracy_score(Y_test,C_ensem_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Pair C Ensemble model is: ', C_ensemble_model_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "C_ensemble_model_custom_mse = mean_squared_error(Y_test,C_ensem_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Pair C Ensemble model is: ', C_ensemble_model_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "C_ensemble_model_custom_msle = mean_squared_log_error(Y_test,C_ensem_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Pair C Ensemble model is: ', C_ensemble_model_custom_msle)\n",
    "\n",
    "#print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,C_ensem_y_pred.argmax(axis=-1),target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,C_ensem_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=100)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, C_ensem_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(15,10), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Pair D\n",
    "\n",
    "pair_D_ensemble_model = ensemble(pair_D, model_input)\n",
    "pair_D_ensemble_model.save('weights/ensemblemodel_pairD.h5')\n",
    "print('The Ensemble Model is Saved')\n",
    "\n",
    "#evaluate accuracy\n",
    "D_ensem_y_pred = pair_D_ensemble_model.predict_generator(validation_generator,\n",
    "                                                         nb_validation_samples/batch_size, workers=1)\n",
    "D_ensemble_model_accuracy = accuracy_score(Y_test,D_ensem_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Pair D_ Ensemble model is: ', D_ensemble_model_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "D_ensemble_model_custom_mse = mean_squared_error(Y_test,D_ensem_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Pair D_ Ensemble model is: ', D_ensemble_model_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "D_ensemble_model_custom_msle = mean_squared_log_error(Y_test,D_ensem_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Pair D_ Ensemble model is: ', D_ensemble_model_custom_msle)\n",
    "\n",
    "#print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,D_ensem_y_pred.argmax(axis=-1),target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,D_ensem_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, A_ensem_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(15,10), dpi=100)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #%% Pair E\n",
    "\n",
    "pair_E_ensemble_model = ensemble(pair_E, model_input)\n",
    "pair_E_ensemble_model.save('weights/ensemblemodel_pairE.h5')\n",
    "print('The Ensemble Model is Saved')\n",
    "\n",
    "#evaluate accuracy\n",
    "E_ensem_y_pred = pair_E_ensemble_model.predict_generator(validation_generator,\n",
    "                                                         nb_validation_samples/batch_size, workers=1)\n",
    "E_ensemble_model_accuracy = accuracy_score(Y_test,E_ensem_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Pair E_ Ensemble model is: ', E_ensemble_model_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "E_ensemble_model_custom_mse = mean_squared_error(Y_test,E_ensem_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Pair E Ensemble model is: ', E_ensemble_model_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "E_ensemble_model_custom_msle = mean_squared_log_error(Y_test,E_ensem_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Pair E Ensemble model is: ', E_ensemble_model_custom_msle)\n",
    "\n",
    "#print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,E_ensem_y_pred.argmax(axis=-1),target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,E_ensem_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "plt.show()\n",
    "\n",
    "#compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, E_ensem_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(15,10), dpi=100)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #%% Pair F\n",
    "\n",
    "pair_F_ensemble_model = ensemble(pair_F, model_input)\n",
    "pair_F_ensemble_model.save('weights/ensemblemodel_pairF.h5')\n",
    "print('The Ensemble Model is Saved')\n",
    "\n",
    "#evaluate accuracy\n",
    "F_ensem_y_pred = pair_F_ensemble_model.predict_generator(validation_generator,\n",
    "                                                         nb_validation_samples/batch_size, workers=1)\n",
    "F_ensemble_model_accuracy = accuracy_score(Y_test,F_ensem_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Pair F_ Ensemble model is: ', F_ensemble_model_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "F_ensemble_model_custom_mse = mean_squared_error(Y_test,F_ensem_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Pair F_ Ensemble model is: ', F_ensemble_model_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "F_ensemble_model_custom_msle = mean_squared_log_error(Y_test,F_ensem_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Pair F_Ensemble model is: ', F_ensemble_model_custom_msle)\n",
    "\n",
    "#print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,F_ensem_y_pred.argmax(axis=-1),target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,F_ensem_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "plt.show()\n",
    "\n",
    "#compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, F_ensem_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(15,10), dpi=100)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #%% Pair G\n",
    "\n",
    "pair_G_ensemble_model = ensemble(pair_G, model_input)\n",
    "pair_G_ensemble_model.save('weights/ensemblemodel_pairG.h5')\n",
    "print('The Ensemble Model is Saved')\n",
    "\n",
    "#evaluate accuracy\n",
    "G_ensem_y_pred = pair_G_ensemble_model.predict_generator(validation_generator,\n",
    "                                                         nb_validation_samples/batch_size, workers=1)\n",
    "G_ensemble_model_accuracy = accuracy_score(Y_test,G_ensem_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Pair G_ Ensemble model is: ', G_ensemble_model_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "G_ensemble_model_custom_mse = mean_squared_error(Y_test,G_ensem_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Pair G_ Ensemble model is: ', G_ensemble_model_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "G_ensemble_model_custom_msle = mean_squared_log_error(Y_test,G_ensem_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Pair G_ Ensemble model is: ', G_ensemble_model_custom_msle)\n",
    "\n",
    "#print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,E_ensem_y_pred.argmax(axis=-1),target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,G_ensem_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "plt.show()\n",
    "\n",
    "#compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, G_ensem_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(20,10), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Pair H\n",
    "\n",
    "pair_H_ensemble_model = ensemble(pair_H, model_input)\n",
    "pair_H_ensemble_model.save('weights/ensemblemodel_pairH.h5')\n",
    "print('The Ensemble Model is Saved')\n",
    "\n",
    "#evaluate accuracy\n",
    "H_ensem_y_pred = pair_H_ensemble_model.predict_generator(validation_generator,\n",
    "                                                         nb_validation_samples/batch_size, workers=1)\n",
    "H_ensemble_model_accuracy = accuracy_score(Y_test,H_ensem_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Pair H_ Ensemble model is: ', H_ensemble_model_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "H_ensemble_model_custom_mse = mean_squared_error(Y_test,H_ensem_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Pair H_ Ensemble model is: ', H_ensemble_model_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "H_ensemble_model_custom_msle = mean_squared_log_error(Y_test,H_ensem_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Pair H_ Ensemble model is: ', H_ensemble_model_custom_msle)\n",
    "\n",
    "#print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,E_ensem_y_pred.argmax(axis=-1),target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,H_ensem_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "plt.show()\n",
    "\n",
    "#compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, H_ensem_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(20,10), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Pair I\n",
    "\n",
    "pair_I_ensemble_model = ensemble(pair_I, model_input)\n",
    "pair_I_ensemble_model.save('weights/ensemblemodel_pairI.h5')\n",
    "print('The Ensemble Model is Saved')\n",
    "\n",
    "#evaluate accuracy\n",
    "I_ensem_y_pred = pair_I_ensemble_model.predict_generator(validation_generator,\n",
    "                                                         nb_validation_samples/batch_size, workers=1)\n",
    "I_ensemble_model_accuracy = accuracy_score(Y_test,I_ensem_y_pred.argmax(axis=-1))\n",
    "print('The accuracy of the Pair I_ Ensemble model is: ', I_ensemble_model_accuracy)\n",
    "\n",
    "#evaluate mean squared error\n",
    "I_ensemble_model_custom_mse = mean_squared_error(Y_test,I_ensem_y_pred.argmax(axis=-1))\n",
    "print('The Mean Squared Error of the Pair I_ Ensemble model is: ', I_ensemble_model_custom_mse)\n",
    "\n",
    "#evaluate mean squared log error\n",
    "I_ensemble_model_custom_msle = mean_squared_log_error(Y_test,I_ensem_y_pred.argmax(axis=-1))  \n",
    "print('The Mean Squared Log Error of the Pair I_ Ensemble model is: ', I_ensemble_model_custom_msle)\n",
    "\n",
    "#print classification report and plot confusion matrix\n",
    "target_names = ['class 0(abnormal)', 'class 1(normal)'] \n",
    "print(classification_report(Y_test,I_ensem_y_pred.argmax(axis=-1),target_names=target_names, digits=4))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test,I_ensem_y_pred.argmax(axis=-1))\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(20,10), dpi=300)\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names)\n",
    "plt.show()\n",
    "\n",
    "#compute the ROC-AUC values\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test, I_ensem_y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "fig=plt.figure(figsize=(20,10), dpi=300)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "major_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "minor_ticks = np.arange(0.0, 1.0, 0.05)\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_yticks(major_ticks)\n",
    "ax.set_yticks(minor_ticks, minor=True)\n",
    "ax.grid(which='both')\n",
    "lw = 1 \n",
    "plt.plot(fpr[1], tpr[1], color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
